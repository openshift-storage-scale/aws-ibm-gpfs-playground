---
# Follows https://www.ibm.com/docs/en/scalecontainernative/5.2.2?topic=cleanup-red-hat-openshift-nodes
# to cleanup all objects
- name: Playbook to cleanup GPFS
  hosts: localhost
  gather_facts: false
  become: false
  vars_files:
    # Use this to override stuff that won't be committed to git
    - ../../overrides.yml
  tasks:
  - name: Delete the fusionaccess
    tags:
      - 1_cleanup
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} delete -f "{{ gpfsfolder }}/fusionaccess.yaml"
    retries: 2
    delay: 5
    register: fusionaccess_ready
    until: fusionaccess_ready is not failed
    ignore_errors: true

  - name: Debug fusionaccess removal errors
    ansible.builtin.debug:
      msg: "{{ fusionaccess_ready.stdout }}"
    when: fusionaccess_ready is failed

  - name: Delete the test deployment
    tags:
      - 1_cleanup
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} delete -f "{{ gpfsfolder }}/test_consume.yaml"
    failed_when: false

  - name: Delete the snapshotclass
    tags:
      - 1_cleanup
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} delete -f "{{ gpfsfolder }}/snapshot.yaml"
    failed_when: false

  - name: Delete the StorageClass
    tags:
      - 2_cleanup
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} delete storageclass ibm-test-sc --ignore-not-found=true
    failed_when: false

  - name: Delete the Filesystem
    tags:
      - 2_cleanup
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} delete filesystem.scale.spectrum.ibm.com -n ibm-spectrum-scale {{ gpfs_fs_name }} --ignore-not-found=true
    retries: 5
    delay: 10
    register: filesystem_delete
    until: filesystem_delete is not failed
    ignore_errors: true

  - name: Debug Filesystem removal errors
    tags:
      - 2_cleanup
    ansible.builtin.debug:
      msg: "{{ filesystem_delete.stdout }}"
    when: filesystem_delete is failed

  - name: Delete the LocalDisk
    tags:
      - 2_cleanup
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} delete localdisk.scale.spectrum.ibm.com -n ibm-spectrum-scale shareddisk1 --ignore-not-found=true
    retries: 5
    delay: 10
    register: localdisk_delete
    until: localdisk_delete is not failed
    ignore_errors: true

  - name: Debug LocalDisk removal errors
    tags:
      - 2_cleanup
    ansible.builtin.debug:
      msg: "{{ localdisk_delete.stdout }}"
    when: localdisk_delete is failed

  - name: Wait for LocalDisk and Filesystem to be deleted
    tags:
      - 2_cleanup
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      # Wait until no LocalDisk or Filesystem resources exist with our names
      LD_COUNT=$({{ oc_bin }} get localdisk.scale.spectrum.ibm.com -n ibm-spectrum-scale shareddisk1 --no-headers 2>/dev/null | wc -l || echo "0")
      FS_COUNT=$({{ oc_bin }} get filesystem.scale.spectrum.ibm.com -n ibm-spectrum-scale {{ gpfs_fs_name }} --no-headers 2>/dev/null | wc -l || echo "0")
      if [ "${LD_COUNT}" -gt 0 ] || [ "${FS_COUNT}" -gt 0 ]; then
        exit 1
      fi
    retries: 10
    delay: 15
    register: cascade_delete
    until: cascade_delete is not failed
    ignore_errors: true

  - name: Delete the cluster
    tags:
      - 2_cleanup
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} delete -f "{{ gpfsfolder }}/cluster.yaml"
    retries: 2
    delay: 5
    register: cluster_ready
    until: cluster_ready is not failed
    ignore_errors: true

  - name: Debug cluster removal errors
    ansible.builtin.debug:
      msg: "{{ cluster_ready.stdout }}"
    when: cluster_ready is failed

  - name: Get worker nodes names
    tags:
      - 3_cleanup
    ansible.builtin.shell: |
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} get nodes -l node-role.kubernetes.io/worker -o name | cut -f2 -d/
    register: worker_nodes_output

  - name: Set worker nodes names fact
    tags:
      - 3_cleanup
    ansible.builtin.set_fact:
      worker_nodes: "{{ worker_nodes_output.stdout_lines }}"

  - name: Clean up local folders
    tags:
      - 3_cleanup
    ansible.builtin.shell: |
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} debug node/{{ item }} -T -- chroot /host sh -c "rm -rf /var/mmfs; rm -rf /var/adm/ras"
    loop: "{{ worker_nodes }}"
