# we need to label the workers so the localdisk
- name: Label the workers
  tags:
    - 6_gpfs
  ansible.builtin.shell: |
    set -ex
    export KUBECONFIG={{ kubeconfig }}
    for node in $({{ oc_bin }} get nodes -l node-role.kubernetes.io/worker -o name)
    do
      {{ oc_bin }} label ${node} scale.spectrum.ibm.com/role=storage
      {{ oc_bin }} label ${node} scale.spectrum.ibm.com/daemon-selector=""
    done

- name: Template the Fusion Cluster object
  ansible.builtin.template:
    src: ../templates/cluster.yaml
    dest: "{{ gpfsfolder }}/cluster.yaml"
  tags:
    - 6_gpfs

- name: Apply the Fusion cluster object
  tags:
    - 6_gpfs
  ansible.builtin.shell: |
    set -ex
    export KUBECONFIG={{ kubeconfig }}
    {{ oc_bin }} apply -f "{{ gpfsfolder }}/cluster.yaml"
  register: fusion_apply
  until: fusion_apply is not failed
  retries: 20
  delay: 20

- name: Wait for fusion pods
  tags:
    - 6_gpfs
  ansible.builtin.shell: |
    set -ex
    export KUBECONFIG={{ kubeconfig }}
    COUNT=$({{ oc_bin }} get pods -n ibm-spectrum-scale -l app.kubernetes.io/name=core --no-headers | grep Running | wc -l)
    NODES=$(oc get nodes -l "node-role.kubernetes.io/worker" --no-headers | wc -l)
    if [ ${COUNT} != ${NODES} ]; then
      exit 1
    fi
  register: fusion_apply
  until: fusion_apply is not failed
  retries: 30
  delay: 30

- name: Get EBS volume info by tag name
  tags:
    - 6_gpfs
  amazon.aws.ec2_vol_info:
    profile: "{{ aws_profile }}"
    region: "{{ ocp_region }}"
    filters:
      "tag:Name": "{{ gpfs_volume_name }}"
  register: volume_info

- name: Fail if there is not exactly one EBS volume with the name
  tags:
    - 6_gpfs
  ansible.builtin.fail:
    msg: "There must be only one EBS volume called {{ gpfs_volume_name }}: {{ volume_info }}"
  when: volume_info.volumes | length != 1

- name: Query LocalVolumeDiscoveryResult to get device path
  tags:
    - 6_gpfs
  ansible.builtin.shell: |
    set -ex
    export KUBECONFIG={{ kubeconfig }}
    {{ oc_bin }} get localvolumediscoveryresult -n {{ operator_namespace }} -o json
  register: lvdr_output
  retries: 20
  delay: 30
  until:
    - lvdr_output is not failed
    - (lvdr_output.stdout | from_json)['items'] | length > 0
    - (lvdr_output.stdout | from_json)['items'][0].status.discoveredDevices is defined
    - (lvdr_output.stdout | from_json)['items'][0].status.discoveredDevices | length > 0

- name: Parse LVDR and extract device path
  tags:
    - 6_gpfs
  ansible.builtin.set_fact:
    lvdr_json: "{{ lvdr_output.stdout | from_json }}"

- name: Debug LVDR structure
  tags:
    - 6_gpfs
  ansible.builtin.debug:
    msg:
      - "LVDR items count: {{ lvdr_json['items'] | length }}"
      - "First LVDR node: {{ lvdr_json['items'][0].spec.nodeName }}"
      - "Discovered devices count: {{ lvdr_json['items'][0].status.discoveredDevices | length }}"

- name: Set device WWN from first discovered device
  tags:
    - 6_gpfs
  ansible.builtin.set_fact:
    ebs_device_wwn: "{{ lvdr_json['items'][0].status.discoveredDevices[0].WWN }}"

- name: Debug device WWN
  tags:
    - 6_gpfs
  ansible.builtin.debug:
    var: ebs_device_wwn

- name: Template the FileSystemClaim
  tags:
    - 6_gpfs
  ansible.builtin.template:
    src: ../templates/filesystemclaim.yaml
    dest: "{{ gpfsfolder }}/filesystemclaim.yaml"

- name: Apply the FileSystemClaim
  tags:
    - 6_gpfs
  ansible.builtin.shell: |
    set -ex
    export KUBECONFIG={{ kubeconfig }}
    {{ oc_bin }} apply -f "{{ gpfsfolder }}/filesystemclaim.yaml"
  retries: 10
  delay: 30
  register: filesystemclaim_apply
  until: filesystemclaim_apply is not failed

- name: Wait for FileSystemClaim to be ready
  tags:
    - 7_gpfs
  ansible.builtin.shell: |
    set -ex
    export KUBECONFIG={{ kubeconfig }}
    {{ oc_bin }} get filesystemclaim -n ibm-spectrum-scale filesystemclaim-sample -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' | grep -q "True"
  retries: 30
  delay: 30
  register: filesystemclaim_ready
  until: filesystemclaim_ready is not failed

- name: Template the snapshotclass
  tags:
    - 7_gpfs
  ansible.builtin.template:
    src: ../templates/snapshot.yaml
    dest: "{{ gpfsfolder }}/snapshot.yaml"

- name: Apply the snapshotclass
  tags:
    - 7_gpfs
  ansible.builtin.shell: |
    set -ex
    export KUBECONFIG={{ kubeconfig }}
    {{ oc_bin }} apply -f "{{ gpfsfolder }}/snapshot.yaml"

- name: Template the test deployment
  tags:
    - 8_gpfs
  ansible.builtin.template:
    src: ../templates/test_consume.yaml
    dest: "{{ gpfsfolder }}/test_consume.yaml"

- name: Apply the test deployment
  tags:
    - 8_gpfs
  ansible.builtin.shell: |
    set -ex
    export KUBECONFIG={{ kubeconfig }}
    {{ oc_bin }} apply -f "{{ gpfsfolder }}/test_consume.yaml"

- block:
  - name: Get EBS volume info by tag name (2)
    tags:
      - 6_gpfs
    amazon.aws.ec2_vol_info:
      profile: "{{ aws_profile }}"
      region: "{{ ocp_region }}"
      filters:
        "tag:Name": "{{ gpfs_volume_name_two }}"
    register: volume_info_two

  - name: Fail if there is not exactly one EBS volume with the name (2)
    tags:
      - 6_gpfs
    ansible.builtin.fail:
      msg: "There must be only one EBS volume called {{ gpfs_volume_name_two }}: {{ volume_info_two }}"
    when: volume_info_two.volumes | length != 1

  - name: Query LocalVolumeDiscoveryResult to get device path (2)
    tags:
      - 6_gpfs
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} get localvolumediscoveryresult -n {{ operator_namespace }} -o json
    register: lvdr_output
    retries: 20
    delay: 30
    until:
      - lvdr_output is not failed
      - (lvdr_output.stdout | from_json)['items'] | length > 0
      - (lvdr_output.stdout | from_json)['items'][0].status.discoveredDevices is defined
      - (lvdr_output.stdout | from_json)['items'][0].status.discoveredDevices | length > 0

  - name: Parse LVDR and extract device path (2)
    tags:
      - 6_gpfs
    ansible.builtin.set_fact:
      lvdr_json: "{{ lvdr_output.stdout | from_json }}"

  - name: Debug LVDR structure (2)
    tags:
      - 6_gpfs
    ansible.builtin.debug:
      msg:
        - "LVDR items count: {{ lvdr_json['items'] | length }}"
        - "First LVDR node: {{ lvdr_json['items'][0].spec.nodeName }}"
        - "Discovered devices count: {{ lvdr_json['items'][0].status.discoveredDevices | length }}"

  - name: Set device WWN from first discovered device (2)
    tags:
      - 6_gpfs
    ansible.builtin.set_fact:
      ebs_device_wwn2: "{{ lvdr_json['items'][0].status.discoveredDevices[0].WWN }}"

  - name: Debug device WWN (2)
    tags:
      - 6_gpfs
    ansible.builtin.debug:
      var: ebs_device_wwn2

  - name: Template the filesystemclaim (2)
    tags:
      - 7_gpfs
    ansible.builtin.template:
      src: ../templates/filesystemclaim2.yaml
      dest: "{{ gpfsfolder }}/filesystemclaim2.yaml"

  - name: Apply the filesystemclaim (2)
    tags:
      - 7_gpfs
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} apply -f "{{ gpfsfolder }}/filesystemclaim2.yaml"
    retries: 10
    delay: 30
    register: filesystem_apply
    until: filesystem_apply is not failed

  - name: Wait for FileSystemClaim to be ready (2)
    tags:
      - 7_gpfs
    ansible.builtin.shell: |
      set -ex
      export KUBECONFIG={{ kubeconfig }}
      {{ oc_bin }} get filesystemclaim -n ibm-spectrum-scale filesystemclaim-sample2 -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' | grep -q "True"
    retries: 30
    delay: 30
    register: filesystemclaim_ready
    until: filesystemclaim_ready is not failed

  when: baremetal_env | bool
